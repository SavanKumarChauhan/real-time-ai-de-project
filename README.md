# âš¡ Real-Time AI-Powered Data Engineering Pipeline with Databricks & GPT

This open-source project showcases a **real-time, AI-enhanced data pipeline** built using the **modern Lakehouse architecture** on **Azure Databricks**. It simulates both **batch and streaming data**, processes it through **Bronze â†’ Silver â†’ Gold layers**, integrates **OpenAIâ€™s GPT** to generate smart sales summaries, and finally renders everything in a live **Databricks dashboard**.

> ğŸš€ Perfect for showcasing Data Engineering, Streaming, GPT Integration, Secure Azure Mounting, and End-to-End Workflow Orchestration skills â€” just like what modern data teams at tech-forward companies need.

---

## ğŸ’¡ What You'll See in This Project
![Real-Time Dashboard](real_time_dashboard/dashboard.JPG)


- ğŸ” **Real-Time Streaming + Batch Ingestion** using Parquet & Delta formats
- ğŸ§¹ **Dirty Data Cleansing & Schema Enforcement**
- ğŸª™ **Bronze â†’ Silver â†’ Gold Lakehouse Layers** with structured processing
- ğŸ¤– **AI-Driven GPT Summaries** generated from Gold data
- ğŸ“Š **Real-Time Sales Dashboard** inside Databricks
- ğŸ” **Enterprise-Grade Security** with Azure Key Vault + Secret Scopes
- ğŸ“ˆ **Fully Orchestrated Pipeline** using Databricks Jobs + Delta Live Tables (DLT)

---

## ğŸ§± Project Architecture

This project follows a modern **Lakehouse + AI design pattern** built on Databricks and Azure. Here's the high-level architecture:

- ğŸ”„ **Data Simulation**: Generates both batch and streaming Parquet files
- ğŸ§ª **Ingestion Layer**:
  - Batch â†’ Ingested via PySpark notebooks to Silver layer
  - Streaming â†’ Ingested using **Delta Live Tables (DLT)** and stored in Silver
- ğŸ§¹ **Transformation Layer**: 
  - Cleansed, validated, enriched in Silver
  - Processed into Gold with analytics-ready columns
- ğŸ¤– **AI Insights Layer**: 
  - Uses **OpenAI GPT-3.5** to summarize Gold data into natural language insights
- ğŸ“Š **Visualization Layer**:
  - Real-time Databricks dashboard (sales trends, categories, GPT summary)
- ğŸ” **Security Layer**:
  - Azure Key Vault + Secret Scopes for secure mounting and key management
- âš™ï¸ **Orchestration**:
  - A Unified Databricks Job manages batch, streaming, AI, and dashboard end-to-end

---

### ğŸ“Œ Architecture Diagram

![Project Architecture](real_time_dashboard/ArchitectureDiagram.png)

---

## ğŸŒŸ Key Features

This project showcases the most in-demand, real-world features companies expect from modern data engineers:

### âš™ï¸ Hybrid Ingestion Layer
- ğŸ”„ Simulates **both batch and streaming data**
- â¬…ï¸ Batch data is ingested using PySpark and stored in Bronze (Parquet)
- ğŸŒŠ Streaming data is ingested using **Delta Live Tables (DLT)**

### ğŸ§¹ Multi-Layer Lakehouse Architecture (Bronze â†’ Silver â†’ Gold)
- ğŸ’¾ Raw â†’ Cleaned â†’ Enriched data flow using **Delta format**
- ğŸ§  Gold layer includes reporting-specific columns (total revenue, year/month/day)

### ğŸ§  AI-Driven Insight Generation
- ğŸ¤– Uses **OpenAI GPT-3.5** to auto-generate sales summaries from Gold layer
- ğŸ” API key is secured with **Azure Key Vault + Databricks Secret Scope**
- ğŸ’¬ Summaries saved to Delta table for real-time dashboard embedding

### ğŸ“Š Real-Time Analytics Dashboard
- ğŸ“‰ Databricks SQL dashboard with:
  - Revenue trends over time
  - Sales by category and store
  - Top 10 best-selling products
  - ğŸ§  GPT-generated sales summary box

### ğŸ” Enterprise-Grade Security
- ğŸ”‘ OAuth-based mounting via **Azure Key Vault**
- ğŸ§¾ Secret scopes hide all credentials and tokens

### ğŸ§© End-to-End Orchestration
- ğŸ” Unified **Databricks Job** executes entire workflow:
  - Batch ingestion
  - Streaming pipeline (DLT)
  - Silver â†’ Gold â†’ GPT â†’ Dashboard
- ğŸ”„ Can be **scheduled or triggered** on demand



