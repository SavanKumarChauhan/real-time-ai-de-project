{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97766c78-2632-40b9-a802-19e1f2688c60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Delete Products data from Bronze and Silver (safe!)\n",
    "# dbutils.fs.rm(\"/mnt/realtimedeai/bronze/batch/products/\", recurse=True)\n",
    "# dbutils.fs.rm(\"/mnt/realtimedeai/silver/batch/products/\", recurse=True)\n",
    "\n",
    "# print(\"âœ… Deleted existing Products data from both Bronze and Silver layers!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b3aea2d-4ec5-479f-824e-e9f72306c915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d78a2d-5fd2-4208-841a-4142c00d1a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# ðŸš€ Data Simulation: Batch Data Generator\n",
    "# Author: Savan's Real-Time AI Data Project\n",
    "# Phase: Data Simulation (Batch)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Step 1: Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Step 2: Initialize Faker for generating fake but realistic data\n",
    "fake = Faker()\n",
    "\n",
    "# Step 3: Set seeds for reproducibility (important for testing and re-runs)\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e7ea002-99cd-4356-8d36-e7a654592c70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# âœ… Step 3: Generate Products Data (Fixed & Clean)\n",
    "# ----------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Set seeds for reproducibility (important!)\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define your category â†’ product mapping (REALISTIC!)\n",
    "category_product_map = {\n",
    "    \"Electronics\": [\"Laptop\", \"Smartphone\", \"Tablet\", \"Camera\", \"Smartwatch\"],\n",
    "    \"Clothing\": [\"T-shirt\", \"Jeans\", \"Jacket\", \"Sneakers\", \"Sweater\"],\n",
    "    \"Grocery\": [\"Rice\", \"Pasta\", \"Olive Oil\", \"Bread\", \"Eggs\"],\n",
    "    \"Beverages\": [\"Coffee\", \"Tea\", \"Juice\", \"Soda\", \"Energy Drink\"],\n",
    "    \"Household\": [\"Detergent\", \"Soap\", \"Toilet Paper\", \"Towel\", \"Dishwasher Tablets\"]\n",
    "}\n",
    "\n",
    "# Deciding the number of products (example: 100)\n",
    "num_products = 100\n",
    "\n",
    "# First, create product_id, base_price, stock (DO NOT CHANGE THIS PART)\n",
    "products_df = pd.DataFrame({\n",
    "    'product_id': range(101, 101 + num_products),\n",
    "    'base_price': np.round(np.random.uniform(2.0, 500.0, num_products), 2),\n",
    "    'stock': np.random.randint(50, 1000, num_products)\n",
    "})\n",
    "\n",
    "# âœ… FIX: Assign proper category and product_name based on mapping\n",
    "def assign_category_and_product():\n",
    "    category = random.choice(list(category_product_map.keys()))\n",
    "    product_name = random.choice(category_product_map[category])\n",
    "    return pd.Series([category, product_name])\n",
    "\n",
    "# Apply the function to replace category and product_name correctly\n",
    "products_df[[\"category\", \"product_name\"]] = products_df.apply(lambda _: assign_category_and_product(), axis=1)\n",
    "\n",
    "# âœ… Final Check: Preview the fixed products data\n",
    "display(products_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b01f70b-494a-4eb2-b956-2965cb0d6b11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# âœ… Step 4: Generate Stores Data\n",
    "# ----------------------------------------\n",
    "\n",
    "# Deciding the number of stores (realistic: 10-50 stores)\n",
    "num_stores = 20\n",
    "\n",
    "# Define regions and store sizes (will be useful later for aggregations)\n",
    "regions = ['Ontario', 'Quebec', 'British Columbia', 'Alberta']\n",
    "store_sizes = ['Small', 'Medium', 'Large']\n",
    "\n",
    "# Generate store catalog\n",
    "stores_df = pd.DataFrame({\n",
    "    'store_id': range(1, 1 + num_stores),\n",
    "    'store_name': [fake.company() for _ in range(num_stores)],\n",
    "    'region': np.random.choice(regions, num_stores),\n",
    "    'city': [fake.city() for _ in range(num_stores)],\n",
    "    'size': np.random.choice(store_sizes, num_stores)\n",
    "})\n",
    "\n",
    "# Check the output\n",
    "display(stores_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eb2887d-8af5-490d-b11d-4e7df75a717c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# âœ… Step 5: Generate Promotions Data\n",
    "# ----------------------------------------\n",
    "\n",
    "# Number of promotions (letâ€™s say about 30 promos for testing)\n",
    "num_promotions = 30\n",
    "\n",
    "# Promotion dates (to be used for valid discount ranges)\n",
    "start_promo_date = datetime(2025, 4, 1)\n",
    "end_promo_date = datetime(2025, 4, 30)\n",
    "\n",
    "# Generate promotions data\n",
    "promotions_df = pd.DataFrame({\n",
    "    'promo_id': range(201, 201 + num_promotions),\n",
    "    'product_id': np.random.choice(products_df['product_id'], num_promotions),  # linking to products table\n",
    "    'discount_percent': np.random.choice([5, 10, 15, 20, 25], num_promotions),\n",
    "    'start_date': [start_promo_date.strftime('%Y-%m-%d')] * num_promotions,\n",
    "    'end_date': [end_promo_date.strftime('%Y-%m-%d')] * num_promotions\n",
    "})\n",
    "\n",
    "# Check the output\n",
    "display(promotions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1e47211-b6fb-48d2-9d5c-6638eaf85fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# âœ… Step 6: Generate Sales Transactions (Batch)\n",
    "# ----------------------------------------\n",
    "\n",
    "# Decide number of sales transactions (let's simulate 2000 realistic rows)\n",
    "num_sales = 2000\n",
    "\n",
    "# Function to generate realistic sales transactions\n",
    "def generate_sales_data(n=num_sales):\n",
    "    sales_data = []\n",
    "    \n",
    "    for transaction_id in range(50001, 50001 + n):\n",
    "        product = products_df.sample(1).iloc[0]  # Random product\n",
    "        store = stores_df.sample(1).iloc[0]      # Random store\n",
    "        quantity = np.random.randint(1, 10)      # Quantity between 1 and 10\n",
    "\n",
    "        # No join with promotions here â€” raw price will be base_price.\n",
    "        price = product['base_price']\n",
    "        total_amount = round(price * quantity, 2)\n",
    "        timestamp = fake.date_time_between(start_date='-10d', end_date='now')\n",
    "        \n",
    "        sales_data.append([\n",
    "            transaction_id,\n",
    "            product['product_id'],\n",
    "            store['store_id'],\n",
    "            quantity,\n",
    "            round(price, 2),\n",
    "            total_amount,\n",
    "            timestamp.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        ])\n",
    "    \n",
    "    sales_df = pd.DataFrame(sales_data, columns=[\n",
    "        'transaction_id', 'product_id', 'store_id',\n",
    "        'quantity', 'price', 'total_amount', 'timestamp'\n",
    "    ])\n",
    "    \n",
    "    return sales_df\n",
    "\n",
    "# Generate the data\n",
    "sales_transactions_df = generate_sales_data()\n",
    "\n",
    "# -----------------------------\n",
    "# Injecting Dirty Data (Very Important)\n",
    "# -----------------------------\n",
    "\n",
    "# Bad data: missing product_id, negative quantity/price, duplicate transaction_id\n",
    "bad_data = pd.DataFrame([\n",
    "    [99999, None, 3, -5, 20.0, -100.0, datetime.now().strftime('%Y-%m-%d %H:%M:%S')],  # Missing product_id, negative qty\n",
    "    [99998, 102, None, 2, -50.0, 100.0, datetime.now().strftime('%Y-%m-%d %H:%M:%S')],  # Missing store_id, negative price\n",
    "    [50001, 101, 1, 3, 15.0, 45.0, datetime.now().strftime('%Y-%m-%d %H:%M:%S')]        # Duplicate transaction_id (intentional!)\n",
    "], columns=sales_transactions_df.columns)\n",
    "\n",
    "# Combine clean + bad data\n",
    "sales_transactions_df = pd.concat([sales_transactions_df, bad_data], ignore_index=True)\n",
    "\n",
    "# Preview the data\n",
    "sales_transactions_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dba24968-c944-451c-8f2e-5fb913aaa231",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert Pandas DataFrame to Spark DataFrame\n",
    "products_sdf = spark.createDataFrame(products_df)\n",
    "stores_sdf = spark.createDataFrame(stores_df)\n",
    "promotions_sdf = spark.createDataFrame(promotions_df)\n",
    "sales_transactions_sdf = spark.createDataFrame(sales_transactions_df)\n",
    "\n",
    "# Define the mount path\n",
    "bronze_path = \"/mnt/realtimedeai/bronze/batch/\"\n",
    "\n",
    "# Create the directory (optional safety)\n",
    "dbutils.fs.mkdirs(bronze_path)\n",
    "\n",
    "# âœ… Write as Parquet (Spark handles DBFS paths directly)\n",
    "products_sdf.write.mode(\"overwrite\").parquet(bronze_path + \"products/\")\n",
    "stores_sdf.write.mode(\"overwrite\").parquet(bronze_path + \"stores/\")\n",
    "promotions_sdf.write.mode(\"overwrite\").parquet(bronze_path + \"promotions/\")\n",
    "sales_transactions_sdf.write.mode(\"overwrite\").parquet(bronze_path + \"sales_transactions/\")\n",
    "\n",
    "print(\"âœ… All batch data successfully written to Bronze container in Parquet format (using Spark)!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "896f2a96-3a57-4631-8922-94f06678ee09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/mnt/realtimedeai/bronze/batch/\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_data_simulation_batch",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
